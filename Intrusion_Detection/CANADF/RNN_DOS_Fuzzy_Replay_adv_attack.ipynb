{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "loading data\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import keras\n",
    "from keras import Sequential, regularizers\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, TimeDistributed, LSTM, LayerNormalization\n",
    "from scipy.stats import mode\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "# Training parameters.\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# from layer_norm import LayerNorm1D\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(\n",
    "    physical_devices[0],True)\n",
    "# run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "\n",
    "batch_size = 1 # 16 no good\n",
    "num_classes = 4\n",
    "epochs = 20\n",
    "first_dim = 40\n",
    "# Number of features\n",
    "feature_idx = 11\n",
    "print('loading data')\n",
    "dataframe = pandas.read_csv(\"dataset/combined_data/2nd_labeled.csv\", header=None)\n",
    "# dataframe = pandas.read_csv(\"dataset/combined_data/test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "<>:6: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n<>:6: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\nC:\\Users\\shahr\\AppData\\Local\\Temp/ipykernel_91216/3646515424.py:6: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n  if datasetlen % first_dim is not 0:\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "data loaded\nMaking Train Validation Test Set\n",
      "{0, 1, 2, 3}\n(78375, 40, 11, 1)\n(78375,)\n(20625, 40, 11, 1)\n(20625,)\n(4125, 40, 11, 1)\n(4125,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "dataset = dataframe.values\n",
    "print('data loaded')\n",
    "print('Making Train Validation Test Set')\n",
    "datasetlen=len(dataset)\n",
    "# print(datasetlen % 10)\n",
    "if datasetlen % first_dim is not 0:\n",
    "    datasetlen = datasetlen-datasetlen % first_dim\n",
    "X = np.array([dataset[i:i+first_dim, 0:feature_idx].astype('float32') for i in range(0, datasetlen, first_dim)])\n",
    "Y = np.array([mode(dataset[i:i+first_dim,feature_idx:].astype(int))[0][0][0] for i in range(0, datasetlen, first_dim)])\n",
    "\n",
    "#cann't do this because it will split all the patterns in car\n",
    "#print(X[0])\n",
    "print(set(Y))\n",
    "X=X.reshape(X.shape[0], first_dim, feature_idx, 1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.05, random_state=42)\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Making Model\n",
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 40, 11, 256)       512       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 40, 11, 256)       1024      \n_________________________________________________________________\ndropout (Dropout)            (None, 40, 11, 256)       0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 40, 11, 512)       131584    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 40, 11, 512)       2048      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 40, 11, 512)       0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 40, 11, 1024)      525312    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 40, 11, 1024)      4096      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 40, 11, 1024)      0         \n_________________________________________________________________\ntime_distributed (TimeDistri (None, 40, 512)           3147776   \n_________________________________________________________________\nlayer_normalization (LayerNo (None, 40, 512)           1024      \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 512)               2099200   \n_________________________________________________________________\ndense_3 (Dense)              (None, 4)                 2052      \n=================================================================\nTotal params: 5,914,628\nTrainable params: 5,911,044\nNon-trainable params: 3,584\n_________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Making Model')\n",
    "model=Sequential()\n",
    "model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.0001), input_shape=(first_dim, feature_idx,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(TimeDistributed(LSTM(512,kernel_regularizer=regularizers.l2(0.0001))))\n",
    "model.add(LayerNormalization())\n",
    "model.add(LSTM(512,kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dense(num_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# # Training.\n",
    "# history_callback = model.fit(X_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(X_val, y_val))\n",
    "\n",
    "# model.save('CAN_RNN_model_1line_2021.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\TF-2.5\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "\n               precision    recall  f1-score   support\n\n           0     0.9864    0.9997    0.9930      3766\n           1     1.0000    1.0000    1.0000       129\n           2     1.0000    0.9722    0.9859        72\n           3     0.9908    0.6835    0.8090       158\n\n    accuracy                         0.9872      4125\n   macro avg     0.9943    0.9139    0.9470      4125\nweighted avg     0.9872    0.9872    0.9861      4125\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model.load_weights('CAN_RNN_model_1line_2021.h5')\n",
    "\n",
    "\n",
    "Y_test = np.argmax(y_test, axis=1)\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "print(\"\\n\", classification_report(Y_test, y_pred,digits=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print('Test loss:', scores[0])\n",
    "# print('Test accuracy:', scores[1])\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"E:\\\\Project\\\\Kari_anomaly_2\\\\Adversarial_attacks\\\\cleverhans\")\n",
    "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "\n",
    "\n",
    "class flags_struct:\n",
    "    def __init__(self,\n",
    "                 nb_epochs: int,\n",
    "                 runs: int,\n",
    "                 eps: float,\n",
    "                 adv_train: bool,\n",
    "                 is_categorical: bool,\n",
    "                 batch_size: int,\n",
    "                 UCR_datasets: list):\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.runs = runs\n",
    "        self.eps = eps\n",
    "        self.adv_train = adv_train\n",
    "        self.is_categorical = is_categorical\n",
    "        self.batch_size = batch_size\n",
    "        self.UCR_datasets = UCR_datasets\n",
    "\n",
    "\n",
    "FLAGS = flags_struct(nb_epochs=2000,\n",
    "                     runs=3,\n",
    "                     eps=0.1,\n",
    "                     adv_train=False,\n",
    "                     is_categorical=False,\n",
    "                     batch_size=1,\n",
    "                     UCR_datasets=['50words'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(4125, 40, 11, 1)\n",
      "\n               precision    recall  f1-score   support\n\n           0     0.9191    0.1901    0.3151      3766\n           1     0.0000    0.0000    0.0000       129\n           2     0.0183    0.8472    0.0357        72\n           3     0.0000    0.0000    0.0000       158\n\n    accuracy                         0.1884      4125\n   macro avg     0.2343    0.2593    0.0877      4125\nweighted avg     0.8395    0.1884    0.2883      4125\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\TF-2.5\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\ProgramData\\Miniconda3\\envs\\TF-2.5\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\ProgramData\\Miniconda3\\envs\\TF-2.5\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nC:\\ProgramData\\Miniconda3\\envs\\TF-2.5\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "X_FSGM_list=[]\n",
    "# for \n",
    "X_FSGM_list.append(fast_gradient_method(model, X_test[0:400,:,:,:], FLAGS.eps, np.inf,y=tf.argmax(tf.cast(y_test[0:400], dtype=tf.int32),1)))\n",
    "X_FSGM_list.append(fast_gradient_method(model, X_test[400:800,:,:,:], FLAGS.eps, np.inf,y=tf.argmax(tf.cast(y_test[400:800], dtype=tf.int32),1)))\n",
    "X_FSGM_list.append(fast_gradient_method(model, X_test[800:1200,:,:,:], FLAGS.eps, np.inf,y=tf.argmax(tf.cast(y_test[800:1200], dtype=tf.int32),1)))\n",
    "X_FSGM_list.append(fast_gradient_method(model, X_test[1200:1600,:,:,:], FLAGS.eps, np.inf,y=tf.argmax(tf.cast(y_test[1200:1600], dtype=tf.int32),1)))\n",
    "X_FSGM_list.append(fast_gradient_method(model, X_test[1600:2000,:,:,:], FLAGS.eps, np.inf,y=tf.argmax(tf.cast(y_test[1600:2000], dtype=tf.int32),1)))\n",
    "X_FSGM_list.append(fast_gradient_method(model, X_test[2000:2400,:,:,:], FLAGS.eps, np.inf,y=tf.argmax(tf.cast(y_test[2000:2400], dtype=tf.int32),1)))\n",
    "X_FSGM_list.append(fast_gradient_method(model, X_test[2400:2800,:,:,:], FLAGS.eps, np.inf,y=tf.argmax(tf.cast(y_test[2400:2800], dtype=tf.int32),1)))\n",
    "X_FSGM_list.append(fast_gradient_method(model, X_test[2800:3200,:,:,:], FLAGS.eps, np.inf,y=tf.argmax(tf.cast(y_test[2800:3200], dtype=tf.int32),1)))\n",
    "X_FSGM_list.append(fast_gradient_method(model, X_test[3200:3600,:,:,:], FLAGS.eps, np.inf,y=tf.argmax(tf.cast(y_test[3200:3600], dtype=tf.int32),1)))\n",
    "X_FSGM_list.append(fast_gradient_method(model, X_test[3600:4000,:,:,:], FLAGS.eps, np.inf,y=tf.argmax(tf.cast(y_test[3600:4000], dtype=tf.int32),1)))\n",
    "X_FSGM_list.append(fast_gradient_method(model, X_test[4000:4125,:,:,:], FLAGS.eps, np.inf,y=tf.argmax(tf.cast(y_test[4000:4125], dtype=tf.int32),1)))\n",
    "\n",
    "\n",
    "X_FSGM=np.concatenate(X_FSGM_list,axis=0)\n",
    "print(X_FSGM.shape)\n",
    "y_FSGM = model.predict_classes(X_FSGM)\n",
    "\n",
    "print(\"\\n\", classification_report(Y_test, y_FSGM,digits=4))\n",
    "\n",
    "# scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print('Test loss:', scores[0])\n",
    "# print('Test accuracy:', scores[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(4125, 40, 11, 1)\n",
      "\n               precision    recall  f1-score   support\n\n           0     0.0000    0.0000    0.0000    3766.0\n           1     0.0000    0.0000    0.0000     129.0\n           2     0.0000    0.0000    0.0000      72.0\n           3     0.0000    0.0000    0.0000     158.0\n\n    accuracy                         0.0000    4125.0\n   macro avg     0.0000    0.0000    0.0000    4125.0\nweighted avg     0.0000    0.0000    0.0000    4125.0\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\TF-2.5\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# X_PGD = projected_gradient_descent(model, X_test, FLAGS.eps, 0.01, 40, np.inf, y=tf.argmax(tf.cast(y_test, dtype=tf.int32),1))\n",
    "# \n",
    "# y_PGD = model.predict_classes(X_PGD)\n",
    "# \n",
    "# print(\"\\n\", classification_report(Y_test, y_PGD,digits=4))\n",
    "\n",
    "X_PGD_list=[]\n",
    "# for \n",
    "X_PGD_list.append(projected_gradient_descent(model, X_test[0:400,:,:,:], FLAGS.eps, 0.01, 40, np.inf,y=tf.argmax(tf.cast(y_test[0:400], dtype=tf.int32),1)))\n",
    "X_PGD_list.append(projected_gradient_descent(model, X_test[400:800,:,:,:], FLAGS.eps, 0.01, 40,  np.inf,y=tf.argmax(tf.cast(y_test[400:800], dtype=tf.int32),1)))\n",
    "X_PGD_list.append(projected_gradient_descent(model, X_test[800:1200,:,:,:], FLAGS.eps, 0.01, 40, np.inf,y=tf.argmax(tf.cast(y_test[800:1200], dtype=tf.int32),1)))\n",
    "X_PGD_list.append(projected_gradient_descent(model, X_test[1200:1600,:,:,:], FLAGS.eps, 0.01, 40, np.inf,y=tf.argmax(tf.cast(y_test[1200:1600], dtype=tf.int32),1)))\n",
    "X_PGD_list.append(projected_gradient_descent(model, X_test[1600:2000,:,:,:], FLAGS.eps, 0.01, 40, np.inf,y=tf.argmax(tf.cast(y_test[1600:2000], dtype=tf.int32),1)))\n",
    "X_PGD_list.append(projected_gradient_descent(model, X_test[2000:2400,:,:,:], FLAGS.eps, 0.01, 40, np.inf,y=tf.argmax(tf.cast(y_test[2000:2400], dtype=tf.int32),1)))\n",
    "X_PGD_list.append(projected_gradient_descent(model, X_test[2400:2800,:,:,:], FLAGS.eps, 0.01, 40, np.inf,y=tf.argmax(tf.cast(y_test[2400:2800], dtype=tf.int32),1)))\n",
    "X_PGD_list.append(projected_gradient_descent(model, X_test[2800:3200,:,:,:], FLAGS.eps, 0.01, 40, np.inf,y=tf.argmax(tf.cast(y_test[2800:3200], dtype=tf.int32),1)))\n",
    "X_PGD_list.append(projected_gradient_descent(model, X_test[3200:3600,:,:,:], FLAGS.eps, 0.01, 40, np.inf,y=tf.argmax(tf.cast(y_test[3200:3600], dtype=tf.int32),1)))\n",
    "X_PGD_list.append(projected_gradient_descent(model, X_test[3600:4000,:,:,:], FLAGS.eps, 0.01, 40, np.inf,y=tf.argmax(tf.cast(y_test[3600:4000], dtype=tf.int32),1)))\n",
    "X_PGD_list.append(projected_gradient_descent(model, X_test[4000:4125,:,:,:], FLAGS.eps, 0.01, 40, np.inf,y=tf.argmax(tf.cast(y_test[4000:4125], dtype=tf.int32),1)))\n",
    "\n",
    "\n",
    "X_PGD=np.concatenate(X_PGD_list,axis=0)\n",
    "print(X_PGD.shape)\n",
    "y_PGD = model.predict_classes(X_PGD)\n",
    "\n",
    "print(\"\\n\", classification_report(Y_test, y_PGD,digits=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}