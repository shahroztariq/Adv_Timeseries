# KDD Paper ID: 61
**Paper Title:** Towards Awareness of Adversarial Vulnerability of Time Series Anomaly Detection Models



# Additional Experiments on UCR Dataset
In addition to all the experiment on state-of-the-art anomaly and intrusion detection system. We also cover general time series classification task where we attack a multilayer perception (MLP), a fully convolutional network and ResNet trained on different dataset from the UCR repository. We conduct an analysis of 71 datasets from the University of California, Riverside (UCR) repository. In future work, we will expand on this experiment by including additional neural networks (MobileNet, EfficientNet, DenseNet, and Inception Time) and datasets (the remainder of the UCR dataset, datasets from the UEA repository). 

We find that the Carlini-Wagner L2 attack provides the best adversarial examples, resulting in the most significant performance degradation. In Figure below, we show some original samples and the corresponding perturbed samples generated by FGSM, PGD, BIM, Carlini-Wagner L2, and MIM attacks on UCR datasets. Also, in Tables below, we present the classification results for MLP, FCN, and ResNet.

|![enter image description here](https://github.com/shahroztariq/KDD61/blob/main/UCR/Samples/Adiac_attacks_2.png) { width=50% }  | ![enter image description here](https://github.com/shahroztariq/KDD61/blob/main/UCR/Samples/Car_attacks_1.png) | ![enter image description here](https://github.com/shahroztariq/KDD61/blob/main/UCR/Samples/Coffee_attacks_1.png)|
|![enter image description here](https://github.com/shahroztariq/KDD61/blob/main/UCR/Samples/DiatomSizeReduction_attacks_0.png)|![enter image description here](https://github.com/shahroztariq/KDD61/blob/main/UCR/Samples/FISH_attacks_0.png)| ![enter image description here](https://github.com/shahroztariq/KDD61/blob/main/UCR/Samples/Meat_attacks_2.png)|
